{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPjr1ionmB1G",
        "outputId": "70d239a0-22ba-4a6a-ad87-aaba94677774"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-2.4.4-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.4)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: torch==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.3.1+cu121)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (2024.6.1)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.3.1->torchvision)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch==2.3.1->torchvision) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.3.1->torchvision)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.13.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2024.7.24)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.3.1->torchvision) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.3.1->torchvision) (1.3.0)\n",
            "Downloading pydicom-2.4.4-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydicom, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pydicom-2.4.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom torchvision tqdm scikit-image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bswB2TIwmsgH",
        "outputId": "23db4d30-6a1f-4c61-b3a7-bd89a1904715"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i9rM9XozmDY2"
      },
      "outputs": [],
      "source": [
        "import pydicom\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torchvision.transforms as transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XiH6lCCzmExF"
      },
      "outputs": [],
      "source": [
        "def load_dicom_image(filepath):\n",
        "    dicom = pydicom.dcmread(filepath)\n",
        "    img = dicom.pixel_array\n",
        "    img = img[:, :, 0] if len(img.shape) == 3 else img\n",
        "    img_resized = cv2.resize(img, (256, 256))\n",
        "    img_normalized = img_resized / img_resized.max()\n",
        "    return img_normalized.astype(np.float32)\n",
        "\n",
        "def load_dicom_mask(filepath):\n",
        "    dicom = pydicom.dcmread(filepath)\n",
        "    mask = dicom.pixel_array\n",
        "    mask = mask[:, :, 0] if len(mask.shape) == 3 else mask\n",
        "    mask_resized = cv2.resize(mask, (256, 256))\n",
        "    mask_binary = (mask_resized > 50).astype(np.float32)\n",
        "    return mask_binary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWrU84b8mGOr"
      },
      "outputs": [],
      "source": [
        "class MRCTDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = load_dicom_image(self.image_paths[idx])\n",
        "        mask = load_dicom_mask(self.mask_paths[idx])\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
        "        return image, mask\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DNP_RjRImIFu"
      },
      "outputs": [],
      "source": [
        "# Paths to datasets\n",
        "root_dir = '/content/drive/MyDrive/z4wc364g79-1/JUH_MR-CT_dataset'\n",
        "mr_image_paths = sorted(glob(os.path.join(root_dir, 'MR/image_MR/*.dcm')))\n",
        "mr_mask_paths = sorted(glob(os.path.join(root_dir, 'MR/mask_MR/*.dcm')))\n",
        "ct_image_paths = sorted(glob(os.path.join(root_dir, 'CT/image_CT/*.dcm')))\n",
        "ct_mask_paths = sorted(glob(os.path.join(root_dir, 'CT/mask_CT/*.dcm')))\n",
        "\n",
        "# Split dataset into training and validation sets\n",
        "train_mr_image_paths, val_mr_image_paths, train_mr_mask_paths, val_mr_mask_paths = train_test_split(\n",
        "    mr_image_paths, mr_mask_paths, test_size=0.2, random_state=42\n",
        ")\n",
        "train_ct_image_paths, val_ct_image_paths, train_ct_mask_paths, val_ct_mask_paths = train_test_split(\n",
        "    ct_image_paths, ct_mask_paths, test_size=0.2, random_state=42\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jjlzvk2LmKsM",
        "outputId": "bbeebedd-fd9b-4d3b-9aae-5b5690eb686b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of augmented MRI images: 2880\n",
            "Number of augmented CT images: 2800\n"
          ]
        }
      ],
      "source": [
        "# Define augmentation transformations\n",
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomRotation(30),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "# Parameters\n",
        "num_augmentations_mri = 40  # For around 2500 images\n",
        "num_augmentations_ct = 40  # For around 2500 images\n",
        "\n",
        "# Custom dataset class to apply augmentations multiple times\n",
        "class AugmentedDataset(Dataset):\n",
        "    def __init__(self, image_paths, mask_paths, transform, num_augmentations):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.transform = transform\n",
        "        self.num_augmentations = num_augmentations\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths) * self.num_augmentations\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        original_idx = idx % len(self.image_paths)\n",
        "        image = load_dicom_image(self.image_paths[original_idx])\n",
        "        mask = load_dicom_mask(self.mask_paths[original_idx])\n",
        "\n",
        "        if self.transform:\n",
        "            augmented = self.transform(image)\n",
        "            mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)  # Add channel dimension\n",
        "        return augmented, mask\n",
        "\n",
        "# Create augmented datasets\n",
        "augmented_mri_dataset = AugmentedDataset(train_mr_image_paths, train_mr_mask_paths, augmentation_transforms, num_augmentations_mri)\n",
        "augmented_ct_dataset = AugmentedDataset(train_ct_image_paths, train_ct_mask_paths, augmentation_transforms, num_augmentations_ct)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 8\n",
        "augmented_mri_dataloader = DataLoader(augmented_mri_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "augmented_ct_dataloader = DataLoader(augmented_ct_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "\n",
        "# Check dataset sizes\n",
        "print(f\"Number of augmented MRI images: {len(augmented_mri_dataset)}\")\n",
        "print(f\"Number of augmented CT images: {len(augmented_ct_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONsSu2uVmMpa"
      },
      "outputs": [],
      "source": [
        "# Create validation datasets without augmentation\n",
        "simple_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "\n",
        "val_mr_dataset = MRCTDataset(val_mr_image_paths, val_mr_mask_paths, transform=simple_transform)\n",
        "val_ct_dataset = MRCTDataset(val_ct_image_paths, val_ct_mask_paths, transform=simple_transform)\n",
        "\n",
        "val_mr_dataloader = DataLoader(val_mr_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "val_ct_dataloader = DataLoader(val_ct_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAaJxU-emQ_m",
        "outputId": "cbf8e129-bf55-4497-dc8e-a1391640036a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of MRI images: 90\n",
            "Number of MRI masks: 90\n",
            "Number of CT images: 88\n",
            "Number of CT masks: 88\n",
            "Number of Training MRI images: 72\n",
            "Number of Training MRI masks: 72\n",
            "Number of Training CT images: 70\n",
            "Number of Training CT masks: 70\n",
            "Number of Validation MRI images: 18\n",
            "Number of Validation MRI masks: 18\n",
            "Number of Validation CT images: 18\n",
            "Number of Validation CT masks: 18\n"
          ]
        }
      ],
      "source": [
        "def check_consistency(image_paths, mask_paths, dataset_name):\n",
        "    print(f\"Number of {dataset_name} images: {len(image_paths)}\")\n",
        "    print(f\"Number of {dataset_name} masks: {len(mask_paths)}\")\n",
        "    assert len(image_paths) == len(mask_paths), f\"Mismatch in number of images and masks for {dataset_name}\"\n",
        "\n",
        "# Check consistency of original datasets\n",
        "check_consistency(mr_image_paths, mr_mask_paths, \"MRI\")\n",
        "check_consistency(ct_image_paths, ct_mask_paths, \"CT\")\n",
        "\n",
        "# Check consistency of training datasets\n",
        "check_consistency(train_mr_image_paths, train_mr_mask_paths, \"Training MRI\")\n",
        "check_consistency(train_ct_image_paths, train_ct_mask_paths, \"Training CT\")\n",
        "\n",
        "# Check consistency of validation datasets\n",
        "check_consistency(val_mr_image_paths, val_mr_mask_paths, \"Validation MRI\")\n",
        "check_consistency(val_ct_image_paths, val_ct_mask_paths, \"Validation CT\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5h4_Kg8mTf-",
        "outputId": "076353b6-7398-46a6-a0d6-58c00fe7b3a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of Augmented MRI images: torch.Size([8, 1, 256, 256])\n",
            "Shape of Augmented MRI masks: torch.Size([8, 1, 256, 256])\n",
            "Shape of Augmented CT images: torch.Size([8, 1, 256, 256])\n",
            "Shape of Augmented CT masks: torch.Size([8, 1, 256, 256])\n",
            "Shape of Validation MRI images: torch.Size([8, 1, 256, 256])\n",
            "Shape of Validation MRI masks: torch.Size([8, 1, 256, 256])\n",
            "Shape of Validation CT images: torch.Size([8, 1, 256, 256])\n",
            "Shape of Validation CT masks: torch.Size([8, 1, 256, 256])\n"
          ]
        }
      ],
      "source": [
        "def check_image_sizes(dataloader, dataset_name):\n",
        "    images, masks = next(iter(dataloader))\n",
        "    print(f\"Shape of {dataset_name} images: {images.shape}\")\n",
        "    print(f\"Shape of {dataset_name} masks: {masks.shape}\")\n",
        "\n",
        "# Check image sizes for augmented datasets\n",
        "check_image_sizes(augmented_mri_dataloader, \"Augmented MRI\")\n",
        "check_image_sizes(augmented_ct_dataloader, \"Augmented CT\")\n",
        "\n",
        "# Check image sizes for validation datasets\n",
        "check_image_sizes(val_mr_dataloader, \"Validation MRI\")\n",
        "check_image_sizes(val_ct_dataloader, \"Validation CT\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_YOenAT66Ou4"
      },
      "source": [
        "Step 1: Defining the CycleGAN architetcure for Image Synthesis.    \n",
        "\n",
        "Implementation of ResNet-based Generator and PatchGAN Discriminator.\n",
        "\n",
        "Ablation Study - II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6JVh68jaGZn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "\n",
        "# ResNet-based generator\n",
        "class ResNetGenerator(nn.Module):\n",
        "    def __init__(self, input_nc, output_nc):\n",
        "        super(ResNetGenerator, self).__init__()\n",
        "        model = models.resnet18(pretrained=True)\n",
        "        self.input_nc = input_nc\n",
        "        self.output_nc = output_nc\n",
        "\n",
        "        # Modify the first convolution layer to accept 1-channel input\n",
        "        if input_nc != 3:\n",
        "            self.model = model\n",
        "            self.model.conv1 = nn.Conv2d(input_nc, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        else:\n",
        "            self.model = model\n",
        "\n",
        "        # Extract layers except the last fully connected layer\n",
        "        self.resnet_layers = nn.Sequential(*list(self.model.children())[:-2])\n",
        "\n",
        "        # Additional layers to upsample to the original image size\n",
        "        self.upsample_layers = nn.Sequential(\n",
        "            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(True),\n",
        "            nn.ConvTranspose2d(32, output_nc, kernel_size=4, stride=2, padding=1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.resnet_layers(x)\n",
        "        x = self.upsample_layers(x)\n",
        "        return x\n",
        "\n",
        "# PatchGAN discriminator\n",
        "class PatchGANDiscriminator(nn.Module):\n",
        "    def __init__(self, input_nc):\n",
        "        super(PatchGANDiscriminator, self).__init__()\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
        "            nn.InstanceNorm2d(512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fhCK3QKj_8nF",
        "outputId": "134e1d72-3211-433c-fcea-1c0a27eaa4f1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# VGG-based feature extractor\n",
        "class VGGFeatureExtractor(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(VGGFeatureExtractor, self).__init__()\n",
        "        vgg = models.vgg19(pretrained=True).features\n",
        "        self.layers = layers\n",
        "        self.vgg = nn.ModuleList([vgg[i] for i in layers])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = []\n",
        "        for i, layer in enumerate(self.vgg):\n",
        "            x = layer(x)\n",
        "            if i in self.layers:\n",
        "                features.append(x)\n",
        "        return features\n",
        "\n",
        "# Instantiate the feature extractor\n",
        "feature_extractor = VGGFeatureExtractor([3, 8, 17]).to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "azUNnl5JhsUS",
        "outputId": "ce7eeacc-755c-4ef7-92f9-53457259c3e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqqluhxBgYV6"
      },
      "source": [
        "Ablation Study - III (Incorporating SSIM Loss in the Training Loop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbFQLOZTgi3q"
      },
      "source": [
        "Ablation Study - II (Training Loop without SSIM Loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1wvFayYvSkX",
        "outputId": "56542e1f-a532-4829-db1b-166f226f9553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (1.4.0.post0)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.26.4)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (24.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.3.1+cu121)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (0.11.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (71.0.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.12.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2024.6.1)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->torchmetrics) (2.3.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->torchmetrics) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->torchmetrics) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->torchmetrics) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_E7Qh6A8lqhd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchmetrics.image as tmi\n",
        "\n",
        "# Define SSIM and PSNR metrics\n",
        "ssim_metric = tmi.StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
        "psnr_metric = tmi.PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
        "\n",
        "# Function to compute SSIM and PSNR using torchmetrics\n",
        "def compute_ssim_psnr(real_img, fake_img):\n",
        "    ssim_score = ssim_metric(fake_img, real_img)\n",
        "    psnr_score = psnr_metric(fake_img, real_img)\n",
        "    return ssim_score.item(), psnr_score.item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kbsWzI0Elq28"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(generator, dataloader, device):\n",
        "    ssim_scores = []\n",
        "    psnr_scores = []\n",
        "\n",
        "    generator.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for real_img, _ in dataloader:\n",
        "            real_img = real_img.to(device)\n",
        "            fake_img = generator(real_img)\n",
        "\n",
        "            # Compute SSIM and PSNR\n",
        "            ssim_score, psnr_score = compute_ssim_psnr(real_img, fake_img)\n",
        "\n",
        "            ssim_scores.append(ssim_score)\n",
        "            psnr_scores.append(psnr_score)\n",
        "\n",
        "    # Compute average SSIM and PSNR\n",
        "    avg_ssim = np.mean(ssim_scores)\n",
        "    avg_psnr = np.mean(psnr_scores)\n",
        "\n",
        "    return avg_ssim, avg_psnr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBIpVeXfgr9q"
      },
      "source": [
        "Result - Ablation Study - II"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YC8bqNf_lrG9",
        "outputId": "807c72ce-a564-4d75-da64-df2170d05e4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRI to CT - SSIM: 0.38917426268259686, PSNR: 5.718809286753337\n",
            "CT to MRI - SSIM: 0.5082509318987528, PSNR: 8.227468490600586\n"
          ]
        }
      ],
      "source": [
        "# Define validation dataloaders\n",
        "val_mr_dataloader = DataLoader(val_mr_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "val_ct_dataloader = DataLoader(val_ct_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Evaluate MRI to CT generator\n",
        "avg_ssim_mri_to_ct, avg_psnr_mri_to_ct = evaluate_model(G_MRI_to_CT, val_mr_dataloader, device)\n",
        "print(f\"MRI to CT - SSIM: {avg_ssim_mri_to_ct}, PSNR: {avg_psnr_mri_to_ct}\")\n",
        "\n",
        "# Evaluate CT to MRI generator\n",
        "avg_ssim_ct_to_mri, avg_psnr_ct_to_mri = evaluate_model(G_CT_to_MRI, val_ct_dataloader, device)\n",
        "print(f\"CT to MRI - SSIM: {avg_ssim_ct_to_mri}, PSNR: {avg_psnr_ct_to_mri}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9L6w6ITCv57k"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchmetrics.image as tmi\n",
        "\n",
        "# Define SSIM and PSNR metrics\n",
        "ssim_metric = tmi.StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
        "psnr_metric = tmi.PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
        "\n",
        "# Function to compute SSIM and PSNR using torchmetrics\n",
        "def compute_ssim_psnr(real_img, fake_img):\n",
        "    ssim_score = ssim_metric(fake_img, real_img)\n",
        "    psnr_score = psnr_metric(fake_img, real_img)\n",
        "    return ssim_score.item(), psnr_score.item()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq91W23-wbhO"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(generator, dataloader, device):\n",
        "    ssim_scores = []\n",
        "    psnr_scores = []\n",
        "\n",
        "    generator.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for real_img, _ in dataloader:\n",
        "            real_img = real_img.to(device)\n",
        "            fake_img = generator(real_img)\n",
        "\n",
        "            # Compute SSIM and PSNR\n",
        "            ssim_score, psnr_score = compute_ssim_psnr(real_img, fake_img)\n",
        "\n",
        "            ssim_scores.append(ssim_score)\n",
        "            psnr_scores.append(psnr_score)\n",
        "\n",
        "    # Compute average SSIM and PSNR\n",
        "    avg_ssim = np.mean(ssim_scores)\n",
        "    avg_psnr = np.mean(psnr_scores)\n",
        "\n",
        "    return avg_ssim, avg_psnr\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfWF38ADgwbV"
      },
      "source": [
        "Result - Ablation Study - III"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lNQdvqBwcV6",
        "outputId": "86c282b8-0cd5-4328-e31f-c9ef555e7f6a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MRI to CT - SSIM: 0.4133886396884918, PSNR: 5.906961441040039\n",
            "CT to MRI - SSIM: 0.5284612476825714, PSNR: 8.28885793685913\n"
          ]
        }
      ],
      "source": [
        "# Define validation dataloaders\n",
        "val_mr_dataloader = DataLoader(val_mr_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "val_ct_dataloader = DataLoader(val_ct_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "# Evaluate MRI to CT generator\n",
        "avg_ssim_mri_to_ct, avg_psnr_mri_to_ct = evaluate_model(G_MRI_to_CT, val_mr_dataloader, device)\n",
        "print(f\"MRI to CT - SSIM: {avg_ssim_mri_to_ct}, PSNR: {avg_psnr_mri_to_ct}\")\n",
        "\n",
        "# Evaluate CT to MRI generator\n",
        "avg_ssim_ct_to_mri, avg_psnr_ct_to_mri = evaluate_model(G_CT_to_MRI, val_ct_dataloader, device)\n",
        "print(f\"CT to MRI - SSIM: {avg_ssim_ct_to_mri}, PSNR: {avg_psnr_ct_to_mri}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
