# Libraries
import os
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from PIL import Image
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Layer, Conv2D, Conv2DTranspose, LeakyReLU, Input, Dropout, Activation
from tensorflow.keras.models import Model
from tensorflow.keras.losses import MeanAbsoluteError, MeanSquaredError

# Define the paths to the image folders
mri_train_image_folder = '/content/drive/MyDrive/z4wc364g79-1/JUH_MR-CT_splits/MR/train/images'
ct_train_image_folder = '/content/drive/MyDrive/z4wc364g79-1/JUH_MR-CT_splits/CT/train/images'
mr_to_ct_path = '/content/drive/MyDrive/z4wc364g79-1/MR TO CT'
ct_to_mr_path = '/content/drive/MyDrive/z4wc364g79-1/CT TO MR'


# --- Data Loading and Preprocessing ---

# Function to load and preprocess images
def load_and_preprocess_images(image_folder, target_size=(256, 256)):
    """Loads images from a folder, converts to grayscale, resizes, and normalizes."""
    images = []
    for filename in os.listdir(image_folder):
        if filename.endswith((".png", ".jpg", ".jpeg", ".tif", ".bmp")):
            image_path = os.path.join(image_folder, filename)
            with Image.open(image_path) as img:
                img = img.convert("L")  # Convert to grayscale
                img = img.resize(target_size)  # Resize to target size
                img_array = np.array(img) / 255.0  # Normalize to [0, 1]
                img_array = np.expand_dims(img_array, axis=-1)  # Add channel dimension for CNN
                images.append(img_array)
    return np.array(images)

# Load and preprocess MRI and CT images
mri_images = load_and_preprocess_images(mri_train_image_folder)
ct_images = load_and_preprocess_images(ct_train_image_folder)

# Print out some information about the processed images
print(f"Number of MRI train images: {mri_images.shape[0]}")
print(f"Shape of MRI images: {mri_images.shape[1:]}")
print(f"Number of CT train images: {ct_images.shape[0]}")
print(f"Shape of CT images: {ct_images.shape[1:]}")


# --- TensorFlow Dataset Creation ---

# Function to create TensorFlow datasets
def create_tf_dataset(images, batch_size):
    """Creates a TensorFlow dataset with shuffling and prefetching."""
    dataset = tf.data.Dataset.from_tensor_slices(images)
    dataset = dataset.shuffle(buffer_size=1000).batch(batch_size)
    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)
    return dataset

# Define parameters
batch_size = 1  # CycleGAN typically uses batch size of 1
target_size = (256, 256)
num_channels = 1  # Grayscale images

# Load and preprocess images (re-run to ensure fresh data for dataset creation)
mri_images = load_and_preprocess_images(mri_train_image_folder, target_size=target_size)
ct_images = load_and_preprocess_images(ct_train_image_folder, target_size=target_size)

# Create TensorFlow datasets
mri_dataset = create_tf_dataset(mri_images, batch_size)
ct_dataset = create_tf_dataset(ct_images, batch_size)

# Print out some information about the datasets
print(f"Number of MRI train batches: {len(mri_dataset)}")
print(f"Number of CT train batches: {len(ct_dataset)}")


# --- Model Architecture (Generator and Discriminator) ---

class InstanceNormalization(Layer):
    """Custom Instance Normalization Layer for the CycleGAN model."""
    def __init__(self, epsilon=1e-5):
        super(InstanceNormalization, self).__init__()
        self.epsilon = epsilon

    def build(self, input_shape):
        self.scale = self.add_weight(name='scale',
                                     shape=input_shape[-1:],
                                     initializer=tf.random_normal_initializer(1., 0.02),
                                     trainable=True)
        self.offset = self.add_weight(name='offset',
                                      shape=input_shape[-1:],
                                      initializer='zeros',
                                      trainable=True)

    def call(self, x):
        mean, variance = tf.nn.moments(x, axes=[1, 2], keepdims=True)
        inv = tf.math.rsqrt(variance + self.epsilon)
        normalized = (x - mean) * inv
        return self.scale * normalized + self.offset

def residual_block(x, filters, kernel_size=3):
    """Defines a residual block for the generator."""
    y = Conv2D(filters, kernel_size, padding='same')(x)
    y = InstanceNormalization()(y)
    y = Activation('relu')(y)
    y = Conv2D(filters, kernel_size, padding='same')(y)
    y = InstanceNormalization()(y)
    return tf.keras.layers.add([x, y])

def build_generator():
    """Builds the U-Net-like generator model with residual blocks."""
    inputs = Input(shape=(256, 256, 1))
    x = Conv2D(64, (7, 7), padding='same')(inputs)
    x = InstanceNormalization()(x)
    x = Activation('relu')(x)

    # Encoder
    x = Conv2D(128, (3, 3), strides=2, padding='same')(x)
    x = InstanceNormalization()(x)
    x = Activation('relu')(x)
    x = Conv2D(256, (3, 3), strides=2, padding='same')(x)
    x = InstanceNormalization()(x)
    x = Activation('relu')(x)

    # Residual blocks
    for _ in range(6):
        x = residual_block(x, 256)

    # Decoder
    x = Conv2DTranspose(128, (3, 3), strides=2, padding='same')(x)
    x = InstanceNormalization()(x)
    x = Activation('relu')(x)
    x = Conv2DTranspose(64, (3, 3), strides=2, padding='same')(x)
    x = InstanceNormalization()(x)
    x = Activation('relu')(x)

    outputs = Conv2D(1, (7, 7), padding='same', activation='tanh')(x)  # Tanh activation outputs values in [-1, 1]
    return Model(inputs, outputs)

def build_discriminator():
    """Builds the PatchGAN discriminator model."""
    inputs = Input(shape=(256, 256, 1))
    x = Conv2D(64, (4, 4), strides=2, padding='same')(inputs)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    x = Conv2D(128, (4, 4), strides=2, padding='same')(x)
    x = InstanceNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    x = Conv2D(256, (4, 4), strides=2, padding='same')(x)
    x = InstanceNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    x = Conv2D(512, (4, 4), strides=2, padding='same')(x)
    x = InstanceNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Dropout(0.25)(x)

    outputs = Conv2D(1, (4, 4), padding='same')(x)
    return Model(inputs, outputs)

# Instantiate the models
generator_g = build_generator()  # Maps MRI to CT
generator_f = build_generator()  # Maps CT to MRI
discriminator_x = build_discriminator()  # Discriminates between real MRI and fake MRI
discriminator_y = build_discriminator()  # Discriminates between real CT and fake CT

# Initialize optimizers
optimizer_g = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)
optimizer_f = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)
optimizer_d_x = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)
optimizer_d_y = tf.keras.optimizers.Adam(1e-4, beta_1=0.5)

# Print model summaries
generator_g.summary()
generator_f.summary()
discriminator_x.summary()
discriminator_y.summary()

# --- Loss Functions and Training Step ---

# Loss functions
loss_obj = MeanSquaredError()

def adversarial_loss(disc_real_output, disc_generated_output):
    """Calculates the adversarial loss for a discriminator."""
    real_loss = loss_obj(tf.ones_like(disc_real_output), disc_real_output)
    generated_loss = loss_obj(tf.zeros_like(disc_generated_output), disc_generated_output)
    total_disc_loss = real_loss + generated_loss
    return total_disc_loss

def cycle_consistency_loss(real_image, cycled_image, lambda_cycle):
    """Calculates the cycle consistency loss."""
    return lambda_cycle * MeanAbsoluteError()(real_image, cycled_image)

def identity_loss(real_image, same_image, lambda_identity):
    """Calculates the identity mapping loss."""
    return lambda_identity * MeanAbsoluteError()(real_image, same_image)

def generator_loss(disc_generated_output, cycled_image, real_image, identity_output, lambda_cycle=10, lambda_identity=5):
    """Calculates the total generator loss, a combination of adversarial, cycle, and identity loss."""
    adv_loss = loss_obj(tf.ones_like(disc_generated_output), disc_generated_output)
    cycle_loss = cycle_consistency_loss(real_image, cycled_image, lambda_cycle)
    id_loss = identity_loss(real_image, identity_output, lambda_identity)
    total_gen_loss = adv_loss + cycle_loss + id_loss
    return total_gen_loss, adv_loss, cycle_loss, id_loss

def discriminator_loss(disc_real_output, disc_generated_output):
    """Calculates the total discriminator loss."""
    real_loss = loss_obj(tf.ones_like(disc_real_output), disc_real_output)
    generated_loss = loss_obj(tf.zeros_like(disc_generated_output), disc_generated_output)
    total_disc_loss = real_loss + generated_loss
    return total_disc_loss

@tf.function
def train_step(real_x, real_y, lambda_cycle=10, lambda_identity=5):
    """Performs a single training step for the CycleGAN model."""
    with tf.GradientTape(persistent=True) as tape:
        # Generate fake images
        fake_y = generator_g(real_x, training=True)  # MRI -> CT
        fake_x = generator_f(real_y, training=True)  # CT -> MRI

        # Cycle images
        cycled_x = generator_f(fake_y, training=True)  # MRI -> CT -> MRI
        cycled_y = generator_g(fake_x, training=True)  # CT -> MRI -> CT

        # Identity images
        same_x = generator_f(real_x, training=True)
        same_y = generator_g(real_y, training=True)

        # Discriminator predictions
        disc_real_x = discriminator_x(real_x, training=True)
        disc_real_y = discriminator_y(real_y, training=True)
        disc_fake_x = discriminator_x(fake_x, training=True)
        disc_fake_y = discriminator_y(fake_y, training=True)

        # Calculate generator losses
        gen_g_loss, adv_loss_g, cycle_loss_g, id_loss_g = generator_loss(disc_fake_y, cycled_x, real_x, same_y, lambda_cycle, lambda_identity)
        gen_f_loss, adv_loss_f, cycle_loss_f, id_loss_f = generator_loss(disc_fake_x, cycled_y, real_y, same_x, lambda_cycle, lambda_identity)

        # Calculate discriminator losses
        disc_x_loss = discriminator_loss(disc_real_x, disc_fake_x)
        disc_y_loss = discriminator_loss(disc_real_y, disc_fake_y)

    # Calculate gradients and apply optimizers
    gradients_of_generator_g = tape.gradient(gen_g_loss, generator_g.trainable_variables)
    gradients_of_generator_f = tape.gradient(gen_f_loss, generator_f.trainable_variables)
    gradients_of_discriminator_x = tape.gradient(disc_x_loss, discriminator_x.trainable_variables)
    gradients_of_discriminator_y = tape.gradient(disc_y_loss, discriminator_y.trainable_variables)

    optimizer_g.apply_gradients(zip(gradients_of_generator_g, generator_g.trainable_variables))
    optimizer_f.apply_gradients(zip(gradients_of_generator_f, generator_f.trainable_variables))
    optimizer_d_x.apply_gradients(zip(gradients_of_discriminator_x, discriminator_x.trainable_variables))
    optimizer_d_y.apply_gradients(zip(gradients_of_discriminator_y, discriminator_y.trainable_variables))

    return gen_g_loss, gen_f_loss, disc_x_loss, disc_y_loss, adv_loss_g, adv_loss_f, cycle_loss_g, cycle_loss_f, id_loss_g, id_loss_f


# --- Training Loop ---

EPOCHS = 25

for epoch in range(EPOCHS):
    gen_g_loss_list = []
    gen_f_loss_list = []
    disc_x_loss_list = []
    disc_y_loss_list = []
    adv_loss_g_list = []
    adv_loss_f_list = []
    cycle_loss_g_list = []
    cycle_loss_f_list = []
    id_loss_g_list = []
    id_loss_f_list = []

    for real_x, real_y in tf.data.Dataset.zip((mri_dataset, ct_dataset)):
        gen_g_loss, gen_f_loss, disc_x_loss, disc_y_loss, adv_loss_g, adv_loss_f, cycle_loss_g, cycle_loss_f, id_loss_g, id_loss_f = train_step(real_x, real_y)
        gen_g_loss_list.append(gen_g_loss)
        gen_f_loss_list.append(gen_f_loss)
        disc_x_loss_list.append(disc_x_loss)
        disc_y_loss_list.append(disc_y_loss)
        adv_loss_g_list.append(adv_loss_g)
        adv_loss_f_list.append(adv_loss_f)
        cycle_loss_g_list.append(cycle_loss_g)
        cycle_loss_f_list.append(cycle_loss_f)
        id_loss_g_list.append(id_loss_g)
        id_loss_f_list.append(id_loss_f)

    # Print epoch results
    print(f"Epoch {epoch + 1} completed")
    print(f"Generator G Loss: {np.mean(gen_g_loss_list)}, Generator F Loss: {np.mean(gen_f_loss_list)}")
    print(f"Discriminator X Loss: {np.mean(disc_x_loss_list)}, Discriminator Y Loss: {np.mean(disc_y_loss_list)}")
    print(f"Adversarial Loss G: {np.mean(adv_loss_g_list)}, Adversarial Loss F: {np.mean(adv_loss_f_list)}")
    print(f"Cycle Consistency Loss G: {np.mean(cycle_loss_g_list)}, Cycle Consistency Loss F: {np.mean(cycle_loss_f_list)}")
    print(f"Identity Loss G: {np.mean(id_loss_g_list)}, Identity Loss F: {np.mean(id_loss_f_list)}")

# Optionally, save the model
generator_g.save('/content/generator_g.h5')
generator_f.save('/content/generator_f.h5')


# --- Visualization and Evaluation ---

# Load a batch of images for visualization and SSIM calculation
mri_batch = next(iter(mri_dataset.batch(5)))
ct_batch = next(iter(ct_dataset.batch(5)))

def visualize_translations(batch, generator, title):
    """Visualizes original and translated images from a batch."""
    plt.figure(figsize=(12, 6))
    num_images = batch.shape[0]
    for i in range(num_images):
        original = batch[i]
        if len(original.shape) < 4:
            original = tf.expand_dims(original, axis=0)

        plt.subplot(2, num_images, i + 1)
        plt.imshow(original[0, :, :, 0], cmap='gray')
        plt.title("Original")
        plt.axis('off')

        prediction = generator(original, training=False)[0]
        plt.subplot(2, num_images, num_images + i + 1)
        plt.imshow(prediction[:, :, 0], cmap='gray')
        plt.title("Translated")
        plt.axis('off')

    plt.suptitle(title)
    plt.show()

# Visualize the translations
visualize_translations(mri_batch, generator_g, "MRI to CT Translations")
visualize_translations(ct_batch, generator_f, "CT to MRI Translations")

def save_translated_images(dataset, generator, save_path):
    """Saves translated images from a dataset to a specified folder."""
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    for i, img in enumerate(dataset):
        if len(img.shape) == 3:
            img = tf.expand_dims(img, axis=0)

        prediction = generator(img, training=False)[0]

        prediction_rescaled = tf.cast((prediction + 1) * 0.5 * 255, tf.uint8)
        prediction_np = prediction_rescaled.numpy().squeeze()

        vmin, vmax = np.min(prediction_np), np.max(prediction_np)

        plt.figure(figsize=(6, 6), dpi=300)
        plt.imshow(prediction_np, cmap='gray', vmin=vmin, vmax=vmax)
        plt.axis('off')
        plt.subplots_adjust(top=1, bottom=0, right=1, left=0, hspace=0, wspace=0)
        plt.savefig(os.path.join(save_path, f'image_{i+1}.png'), format='png', bbox_inches='tight', pad_inches=0)
        plt.close()

        if (i + 1) % 100 == 0:
            print(f"Saved {i + 1} images...")

# Save all translated images
save_translated_images(ct_dataset, generator_f, ct_to_mr_path)
save_translated_images(mri_dataset, generator_g, mr_to_ct_path)


def visualize_and_calculate_ssim(batch, generator, title):
    """Visualizes translations and calculates the SSIM score for a batch."""
    plt.figure(figsize=(12, 6))
    num_images = batch.shape[0]
    ssim_scores = []

    for i in range(num_images):
        original = batch[i]
        if len(original.shape) < 4:
            original = tf.expand_dims(original, axis=0)

        translated = generator(original, training=False)[0]

        # SSIM requires float32 and values in [0, 1]
        original_norm = tf.cast(original, tf.float32)
        translated_norm = tf.cast((translated + 1) * 0.5, tf.float32) # Denormalize from [-1, 1] to [0, 1]

        ssim_score = tf.image.ssim(original_norm, translated_norm, max_val=1.0)
        ssim_score_value = ssim_score.numpy()[0]
        ssim_scores.append(ssim_score_value)

        plt.subplot(2, num_images, i + 1)
        plt.imshow(original[0, :, :, 0], cmap='gray')
        plt.title(f"Original\nSSIM: {ssim_score_value:.3f}")
        plt.axis('off')

        plt.subplot(2, num_images, num_images + i + 1)
        plt.imshow(translated[:, :, 0], cmap='gray')
        plt.title("Translated")
        plt.axis('off')

    plt.suptitle(title)
    plt.show()

    average_ssim = tf.reduce_mean(tf.convert_to_tensor(ssim_scores))
    return average_ssim

# Calculate and visualize SSIM for a batch
average_ssim_mri = visualize_and_calculate_ssim(mri_batch, generator_g, "MRI to CT Translations")
average_ssim_ct = visualize_and_calculate_ssim(ct_batch, generator_f, "CT to MRI Translations")

print("Average SSIM MRI to CT:", average_ssim_mri.numpy())
print("Average SSIM CT to MRI:", average_ssim_ct.numpy())


def calculate_ssim_for_dataset(dataset, generator):
    """Calculates the average SSIM score for an entire dataset."""
    ssim_scores = []

    for original in dataset:
        if len(original.shape) < 4:
            original = tf.expand_dims(original, axis=0)

        translated = generator(original, training=False)[0]

        original_norm = tf.cast(original, tf.float32)
        translated_norm = tf.cast((translated + 1) * 0.5, tf.float32)

        ssim_score = tf.image.ssim(original_norm, translated_norm, max_val=1.0)
        ssim_scores.append(ssim_score.numpy()[0])

    average_ssim = tf.reduce_mean(tf.convert_to_tensor(ssim_scores))
    return average_ssim

# Calculate the average SSIM for the entire datasets
average_ssim_mri_full = calculate_ssim_for_dataset(mri_dataset, generator_g)
average_ssim_ct_full = calculate_ssim_for_dataset(ct_dataset, generator_f)

print("Average SSIM MRI to CT (full dataset):", average_ssim_mri_full.numpy())
print("Average SSIM CT to MRI (full dataset):", average_ssim_ct_full.numpy())
