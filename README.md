# ğŸ§  Unpaired MRI â†” CT Image Translation for Brain Tumour Segmentation

A deep learning framework using **CycleGAN** for unpaired **MRI â†” CT image translation**, aimed at bridging modality gaps in medical imaging for better **brain tumour segmentation**.  
This approach applies **Generative AI (GenAI)** concepts to medical imaging, enabling cross-modality synthesis without paired datasets, improving segmentation in low-data or low-resource clinical settings.

---

## ğŸ¤– Introduction to Generative AI

**Generative AI (GenAI)** refers to a branch of Artificial Intelligence focused on creating new content â€” such as images, text, audio, or video â€” that resembles real-world data.  
Unlike traditional AI models that classify or predict from existing inputs, generative models **learn data distributions** and can produce synthetic, yet realistic, outputs.

In medical imaging, Generative AI can:
- **Generate synthetic scans** to augment limited datasets.
- **Translate between modalities** (e.g., MRI â†” CT).
- **Improve cross-domain performance** in downstream tasks like segmentation or diagnosis.

Popular Generative AI approaches include:
- **GANs (Generative Adversarial Networks)**
- **VAEs (Variational Autoencoders)**
- **Diffusion Models**

---

## ğŸ§  What are GANs?

A **Generative Adversarial Network (GAN)**, introduced by Goodfellow et al. (2014), is a framework with two neural networks competing in a zero-sum game:

- **Generator (G)**: Produces synthetic samples from random noise or a source domain.
- **Discriminator (D)**: Tries to distinguish between real and synthetic samples.

Training Process:
1. The generator tries to produce outputs indistinguishable from real data.
2. The discriminator evaluates whether the sample is real or fake.
3. Both models improve iteratively â€” the generator gets better at â€œfoolingâ€ the discriminator, and the discriminator gets better at spotting fakes.

This **adversarial training** produces highly realistic synthetic data.

---

## ğŸ”„ From GAN to CycleGAN

While standard GANs require paired data (e.g., an MRI image and its exact CT counterpart), **CycleGAN** (Zhu et al., 2017) enables **unpaired image-to-image translation**.

**Key innovation:**  
CycleGAN introduces **cycle-consistency** â€” if you translate an image from Domain A â†’ Domain B â†’ back to Domain A, you should retrieve the original image.

---

## ğŸ— CycleGAN Architecture

### Components:
1. **Two Generators:**
   - \( G_{MRI \to CT} \): Converts MRI images into CT-like images.
   - \( G_{CT \to MRI} \): Converts CT images into MRI-like images.

2. **Two Discriminators:**
   - \( D_{CT} \): Distinguishes between real CT and generated CT images.
   - \( D_{MRI} \): Distinguishes between real MRI and generated MRI images.

### Loss Functions:
- **Adversarial Loss**: Encourages generated images to be indistinguishable from real ones in the target domain.
- **Cycle-Consistency Loss**: Ensures Aâ†’Bâ†’A returns the original input.
- **Identity Loss**: Ensures that translating an image already in the target domain doesnâ€™t alter it unnecessarily.
- **SSIM Loss (Structural Similarity)**: Preserves anatomical structures.
- **Feature Adaptation Loss**: Aligns high-level features between domains using pretrained networks.

![CycleGAN Architecture](assets/cyclegan_architecture.png)

---

## ğŸ“œ Problem Statement

**Context:**
- MRI offers better soft tissue contrast â€” ideal for tumour localisation.
- CT is faster, cheaper, and better for bone imaging.

**Challenge:**  
Segmentation models trained on MRI often fail on CT, and vice versa, due to **domain shift** â€” statistical differences in pixel intensity, contrast, and textures between modalities.

**Real-world limitation:**  
Acquiring paired MRI and CT scans for the same patients is rare and expensive.  
Thus, we need an **unpaired translation** approach to bridge the modality gap.

**Goal:**  
Translate between MRI and CT while preserving structural and pathological information, enabling improved cross-modality segmentation.

---

## ğŸ“‚ Dataset

- **Source**: Jordan University Hospital (JUH)
- **Patients**: 20
- **Images**: 178 axial 2D slices (90 MRI, 88 CT), resized to 256Ã—256
- **Labels**: Tumour masks annotated by radiologists
- **Setting**: Unpaired MRI and CT datasets (different patients for each modality)

**Example Images with Masks:**
![Dataset with Masks](assets/dataset_masks.png)

---

## ğŸ›  Preprocessing

Preprocessing ensures model stability and better generalisation.

1. Convert to **grayscale**
2. Resize to **256Ã—256**
3. Normalise pixel values to [0, 1]
4. Add channel dimension
5. Augmentation:
   - Rotations (Â±30Â°)
   - Horizontal & vertical flips
   - Contrast changes

**Pipeline:**
![Preprocessing Pipeline](assets/preprocessing_pipeline.png)

---

## ğŸ“‹ Methodology

### 1ï¸âƒ£ CycleGAN Translation
- Unpaired training between MRI and CT.
- Feature adaptation via pretrained ResNet/VGG features.
- Additional SSIM loss for structural fidelity.

### 2ï¸âƒ£ U-Net Segmentation
- Evaluates impact of synthetic data on tumour segmentation.
- Metrics: Dice Coefficient & IoU.

### 3ï¸âƒ£ Evaluation
- Compare baseline segmentation vs segmentation trained with synthetic modality augmentation.

---

## ğŸ–¼ Sample Translations

MRI â†’ CT (top) and CT â†’ MRI (bottom):

![Sample Translations](assets/sample_translations.png)

---

## ğŸ“Š Segmentation Results

Segmentation metrics visualised below:

![Segmentation Metrics](assets/segmentation_metrics.png)

---

## ğŸ“š Key Takeaways

- **Generative AI in medical imaging** can help bridge modality gaps.
- **CycleGAN** enables unpaired MRIâ†”CT translation, preserving critical structures.
- **Feature adaptation + SSIM loss** improves perceptual quality (SSIM â†‘ vs baseline GANs).
- Downstream segmentation performance benefits from synthetic modality augmentation.

---

## ğŸ“§ Contact

**Author:** Suchit Pathak  
ğŸ“© **Email:** suchitpathak0807@gmail.com  
ğŸ’» **GitHub:** [github.com/Suchit0807](https://github.com/Suchit0807)  
ğŸŒ **Portfolio:** [suchit0807.github.io/suchit-portfolio](https://suchit0807.github.io/suchit-portfolio/)  
ğŸŒ **LinkedIn:** [linkedin.com/in/suchitpathak](https://linkedin.com/in/suchitpathak)
---

**â­ If you found this work useful, please consider starring the repo!**

