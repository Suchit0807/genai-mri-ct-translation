<h1 align="left">ğŸ§  Unpaired MRI â†” CT Image Translation for Brain Tumour Segmentation</h1>

<p align="left">
A <b>CycleGAN-based</b> deep learning framework for unpaired MRI â†” CT translation, reducing domain shift in medical imaging and improving brain tumour segmentation performance.
</p>

---

## ğŸ“– Introduction

**Generative AI (GenAI)** is a branch of AI focused on creating new, realistic data â€” such as images, text, or audio â€” by learning the underlying patterns of existing data.  
In **medical imaging**, Generative AI can:

- Create **synthetic scans** to augment small datasets.
- Translate between modalities (e.g., MRI â†” CT) for cross-domain applications.
- Improve model robustness and generalisation.

**Generative Adversarial Networks (GANs)** are a core GenAI technology, consisting of:

1. **Generator (G)** â€” Creates synthetic data.
2. **Discriminator (D)** â€” Distinguishes real from synthetic data.

They are trained together in an adversarial loop, where the generator improves at â€œfoolingâ€ the discriminator, and the discriminator improves at spotting fakes.

---

## ğŸ”„ CycleGAN Overview

**CycleGAN** extends GANs for **unpaired image-to-image translation**, solving the problem of requiring paired datasets.  
It learns two mappings simultaneously:

- \( G_{MRI \to CT} \) â€” Translates MRI images to CT-like images.
- \( G_{CT \to MRI} \) â€” Translates CT images to MRI-like images.

**Key concepts in CycleGAN:**
- **Adversarial Loss** â€” Makes generated images realistic.
- **Cycle Consistency Loss** â€” Ensures \( MRI \to CT \to MRI \) returns the original MRI (and vice versa).
- **Identity Loss** â€” Prevents unnecessary changes when input is already in target domain.
- **SSIM Loss** â€” Preserves structural similarity.
- **Feature Adaptation Loss** â€” Aligns high-level features using pretrained networks.

<p align="center">
  <img src="assets/cyclegan_architecture.png" alt="CycleGAN Architecture" width="75%">
</p>

---

## ğŸ“œ Problem Statement

- **MRI** â€” High soft-tissue contrast, better tumour visibility.
- **CT** â€” Faster, cheaper, better for bone structures.

**Domain shift problem:** Models trained on one modality perform poorly on the other due to differences in contrast, noise, and intensity distribution.  
**Challenge:** Paired MRIâ€“CT datasets are rare and expensive to obtain.

**Our goal:** Develop an **unpaired translation model** that preserves anatomy while enabling **cross-modality segmentation**.

---

## ğŸ“‚ Dataset

- **Source**: Jordan University Hospital (JUH)
- **Patients**: 20  
- **Images**: 178 axial 2D slices (90 MRI, 88 CT)  
- **Size**: 256 Ã— 256  
- **Annotations**: Tumour masks by radiologists  
- **Setting**: MRI and CT are from different patients (unpaired)

<p align="center">
  <img src="assets/dataset_masks.png" alt="Dataset with Masks" width="70%">
</p>

---

## ğŸ›  Preprocessing Pipeline

1. **Convert to Grayscale** â€” Focus on structural details.  
2. **Resize to 256 Ã— 256** â€” Standardise input size.  
3. **Normalise pixel values** â€” Range [0, 1].  
4. **Add channel dimension** â€” For model compatibility.  
5. **Data Augmentation**:
   - Â±30Â° rotations  
   - Horizontal/vertical flips  
   - Contrast adjustments  

<p align="center">
  <img src="assets/preprocessing_pipeline.png" alt="Preprocessing Pipeline" width="70%">
</p>

---

## ğŸ“‹ Methodology

### **1ï¸âƒ£ CycleGAN Translation**
- Two generators and discriminators for bidirectional mapping.
- Extra **SSIM loss** for structural preservation.
- **Feature adaptation** using pretrained ResNet/VGG to align domain features.

### **2ï¸âƒ£ U-Net Segmentation**
- Standard U-Net with skip connections for tumour segmentation.
- Evaluates cross-modality generalisation with and without synthetic images.

---

## ğŸ–¼ Sample Translations

**Top:** MRI â†’ CT  
**Bottom:** CT â†’ MRI  

<p align="center">
  <img src="assets/sample_translations.png" alt="Sample Translations" width="80%">
</p>

---

## ğŸ“Š Segmentation Results

<p align="center">
  <img src="assets/segmentation_metrics.png" alt="Segmentation Metrics" width="70%">
</p>

**Key Observations:**
- Within-modality performance is strong (MRI Dice: **0.8792**, CT Dice: **0.6646**).
- Cross-modality performance drops significantly, confirming **domain shift**.
- **Feature adaptation + SSIM loss** improves CTâ†’MRI SSIM from 0.360 (DiscoGAN) to **0.5285**.

---

## ğŸ“š Key Takeaways

- **Generative AI** can effectively bridge modality gaps in medical imaging.  
- **CycleGAN** enables realistic, unpaired MRI â†” CT translation while preserving anatomy.  
- **Structural similarity (SSIM) and feature adaptation** improve perceptual and quantitative quality.  
- Augmenting segmentation training with synthetic modalities can improve cross-domain performance.

---

## ğŸ“§ Contact

**Author:** Suchit Pathak  
ğŸ“© **Email:** suchitpathak0807@gmail.com  
ğŸ’» **GitHub:** [github.com/Suchit0807](https://github.com/Suchit0807)  
ğŸŒ **Portfolio:** [suchit0807.github.io/suchit-portfolio](https://suchit0807.github.io/suchit-portfolio/)  
ğŸŒ **LinkedIn:** [linkedin.com/in/suchitpathak](https://linkedin.com/in/suchitpathak)

---

**â­ If you found this work useful, please consider starring the repo!**

